{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91718,"databundleVersionId":12738969,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.486142Z","iopub.execute_input":"2025-07-07T10:01:03.486464Z","iopub.status.idle":"2025-07-07T10:01:03.493033Z","shell.execute_reply.started":"2025-07-07T10:01:03.486442Z","shell.execute_reply":"2025-07-07T10:01:03.492140Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e7/sample_submission.csv\n/kaggle/input/playground-series-s5e7/train.csv\n/kaggle/input/playground-series-s5e7/test.csv\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Dataset Preparation","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.496382Z","iopub.execute_input":"2025-07-07T10:01:03.496846Z","iopub.status.idle":"2025-07-07T10:01:03.537905Z","shell.execute_reply.started":"2025-07-07T10:01:03.496808Z","shell.execute_reply":"2025-07-07T10:01:03.536966Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.539538Z","iopub.execute_input":"2025-07-07T10:01:03.540042Z","iopub.status.idle":"2025-07-07T10:01:03.569703Z","shell.execute_reply.started":"2025-07-07T10:01:03.540008Z","shell.execute_reply":"2025-07-07T10:01:03.569008Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 18524 entries, 0 to 18523\nData columns (total 9 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   id                         18524 non-null  int64  \n 1   Time_spent_Alone           17334 non-null  float64\n 2   Stage_fear                 16631 non-null  object \n 3   Social_event_attendance    17344 non-null  float64\n 4   Going_outside              17058 non-null  float64\n 5   Drained_after_socializing  17375 non-null  object \n 6   Friends_circle_size        17470 non-null  float64\n 7   Post_frequency             17260 non-null  float64\n 8   Personality                18524 non-null  object \ndtypes: float64(5), int64(1), object(3)\nmemory usage: 1.3+ MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_data.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.570421Z","iopub.execute_input":"2025-07-07T10:01:03.570634Z","iopub.status.idle":"2025-07-07T10:01:03.588438Z","shell.execute_reply.started":"2025-07-07T10:01:03.570617Z","shell.execute_reply":"2025-07-07T10:01:03.587536Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"id                           18524\nTime_spent_Alone                12\nStage_fear                       2\nSocial_event_attendance         11\nGoing_outside                    8\nDrained_after_socializing        2\nFriends_circle_size             16\nPost_frequency                  11\nPersonality                      2\ndtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Converting text data to binomial data","metadata":{}},{"cell_type":"code","source":"# convert text data to numerical data Stage\n# Check what you're working with\nprint(train_data['Stage_fear'].value_counts())\nprint(train_data['Stage_fear'].unique())\n\nprint(\"\\n\")\nprint(train_data['Drained_after_socializing'].value_counts())\nprint(train_data['Drained_after_socializing'].unique())\n\nprint(\"\\n\")\nprint(train_data['Personality'].value_counts())\nprint(train_data['Personality'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.589508Z","iopub.execute_input":"2025-07-07T10:01:03.589812Z","iopub.status.idle":"2025-07-07T10:01:03.611321Z","shell.execute_reply.started":"2025-07-07T10:01:03.589763Z","shell.execute_reply":"2025-07-07T10:01:03.610212Z"}},"outputs":[{"name":"stdout","text":"Stage_fear\nNo     12609\nYes     4022\nName: count, dtype: int64\n['No' 'Yes' nan]\n\n\nDrained_after_socializing\nNo     13313\nYes     4062\nName: count, dtype: int64\n['No' nan 'Yes']\n\n\nPersonality\nExtrovert    13699\nIntrovert     4825\nName: count, dtype: int64\n['Extrovert' 'Introvert']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Convert to binary\n# train data\ntrain_data['Stage_fear'] = train_data['Stage_fear'].map({'Yes': 1, 'No': 0})\ntrain_data['Drained_after_socializing'] = train_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\ntrain_data['Personality'] = train_data['Personality'].map({'Extrovert': 1, 'Introvert': 0})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.613430Z","iopub.execute_input":"2025-07-07T10:01:03.613716Z","iopub.status.idle":"2025-07-07T10:01:03.645521Z","shell.execute_reply.started":"2025-07-07T10:01:03.613695Z","shell.execute_reply":"2025-07-07T10:01:03.643897Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.647099Z","iopub.execute_input":"2025-07-07T10:01:03.647454Z","iopub.status.idle":"2025-07-07T10:01:03.689510Z","shell.execute_reply.started":"2025-07-07T10:01:03.647423Z","shell.execute_reply":"2025-07-07T10:01:03.687956Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"          id  Time_spent_Alone  Stage_fear  Social_event_attendance  \\\n0          0               0.0         0.0                      6.0   \n1          1               1.0         0.0                      7.0   \n2          2               6.0         1.0                      1.0   \n3          3               3.0         0.0                      7.0   \n4          4               1.0         0.0                      4.0   \n...      ...               ...         ...                      ...   \n18519  18519               3.0         0.0                      7.0   \n18520  18520               1.0         NaN                      6.0   \n18521  18521               7.0         1.0                      1.0   \n18522  18522               NaN         1.0                      1.0   \n18523  18523               1.0         0.0                      8.0   \n\n       Going_outside  Drained_after_socializing  Friends_circle_size  \\\n0                4.0                        0.0                 15.0   \n1                3.0                        0.0                 10.0   \n2                0.0                        NaN                  3.0   \n3                3.0                        0.0                 11.0   \n4                4.0                        0.0                 13.0   \n...              ...                        ...                  ...   \n18519            3.0                        0.0                  9.0   \n18520            7.0                        0.0                  6.0   \n18521            1.0                        1.0                  1.0   \n18522            0.0                        1.0                  5.0   \n18523            6.0                        0.0                  4.0   \n\n       Post_frequency  Personality  \n0                 5.0            1  \n1                 8.0            1  \n2                 0.0            0  \n3                 5.0            1  \n4                 NaN            1  \n...               ...          ...  \n18519             7.0            1  \n18520             5.0            1  \n18521             NaN            0  \n18522             2.0            0  \n18523             7.0            1  \n\n[18524 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Time_spent_Alone</th>\n      <th>Stage_fear</th>\n      <th>Social_event_attendance</th>\n      <th>Going_outside</th>\n      <th>Drained_after_socializing</th>\n      <th>Friends_circle_size</th>\n      <th>Post_frequency</th>\n      <th>Personality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>8.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18519</th>\n      <td>18519</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18520</th>\n      <td>18520</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18521</th>\n      <td>18521</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18522</th>\n      <td>18522</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18523</th>\n      <td>18523</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>18524 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_data = train_data.drop('id',axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.690684Z","iopub.execute_input":"2025-07-07T10:01:03.691037Z","iopub.status.idle":"2025-07-07T10:01:03.698806Z","shell.execute_reply.started":"2025-07-07T10:01:03.691015Z","shell.execute_reply":"2025-07-07T10:01:03.697743Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training Dataset Pipeline","metadata":{}},{"cell_type":"code","source":"train_data.iloc[:, :-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.699955Z","iopub.execute_input":"2025-07-07T10:01:03.700348Z","iopub.status.idle":"2025-07-07T10:01:03.734118Z","shell.execute_reply.started":"2025-07-07T10:01:03.700320Z","shell.execute_reply":"2025-07-07T10:01:03.733111Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"       Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n0                   0.0         0.0                      6.0            4.0   \n1                   1.0         0.0                      7.0            3.0   \n2                   6.0         1.0                      1.0            0.0   \n3                   3.0         0.0                      7.0            3.0   \n4                   1.0         0.0                      4.0            4.0   \n...                 ...         ...                      ...            ...   \n18519               3.0         0.0                      7.0            3.0   \n18520               1.0         NaN                      6.0            7.0   \n18521               7.0         1.0                      1.0            1.0   \n18522               NaN         1.0                      1.0            0.0   \n18523               1.0         0.0                      8.0            6.0   \n\n       Drained_after_socializing  Friends_circle_size  Post_frequency  \n0                            0.0                 15.0             5.0  \n1                            0.0                 10.0             8.0  \n2                            NaN                  3.0             0.0  \n3                            0.0                 11.0             5.0  \n4                            0.0                 13.0             NaN  \n...                          ...                  ...             ...  \n18519                        0.0                  9.0             7.0  \n18520                        0.0                  6.0             5.0  \n18521                        1.0                  1.0             NaN  \n18522                        1.0                  5.0             2.0  \n18523                        0.0                  4.0             7.0  \n\n[18524 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time_spent_Alone</th>\n      <th>Stage_fear</th>\n      <th>Social_event_attendance</th>\n      <th>Going_outside</th>\n      <th>Drained_after_socializing</th>\n      <th>Friends_circle_size</th>\n      <th>Post_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18519</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>18520</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>18521</th>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18522</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>18523</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>7.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18524 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\nX = train_data.iloc[:, :-1].copy()\n\ny = train_data['Personality'].copy()\n\n# Split into 80% train, 20% validation\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, \n    test_size=0.2,      # 20% for validation\n    random_state=42,    # For reproducibility\n    stratify=y          # Maintains class distribution (for classification)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.735130Z","iopub.execute_input":"2025-07-07T10:01:03.735405Z","iopub.status.idle":"2025-07-07T10:01:03.760330Z","shell.execute_reply.started":"2025-07-07T10:01:03.735384Z","shell.execute_reply":"2025-07-07T10:01:03.759370Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# AutomML Approach using Optuna Library","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nimport optuna\nimport numpy as np\nfrom time import time\n\n# create an OptunaAutoML Class\nclass AutoMLOptuna:\n    \"\"\"\n    An AutoML Algorithm to search for the best algorithm for binary classification\n    Uses StandardScaler for scaling and SimpleImputer for handling missing values.\n    Includes SVC, XGBoost, SVM, LDA, RandomForest, Neural Network, Naive Bayes, and Decision Trees\n    \"\"\"\n    def __init__(self, X_train, X_test, y_train, y_test, numeric_features=None, categorical_features=None, models=None):\n        \"\"\"\n        X_train, X_test: Input training and test data\n        y_train, y_test: Input binary classification labels (0 and 1)\n        numeric_features: List of numeric column names\n        categorical_features: List of categorical column names\n        models: List of specific models to use (optional)\n        \"\"\"\n        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n        self.numeric_features = numeric_features\n        self.categorical_features = categorical_features\n        self.models = models\n\n    def create_model(self, trial, models=None):\n        # Create preprocessing pipeline with SimpleImputer and StandardScaler\n        numeric_transformer = Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n            ('scaler', StandardScaler())  # Standard scaling only\n        ])\n        \n        categorical_transformer = Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='most_frequent'))  # Handle missing categorical values\n        ])\n\n        # Column transformer\n        if self.numeric_features is not None and self.categorical_features is not None:\n            transformer = ColumnTransformer([\n                ('numeric', numeric_transformer, self.numeric_features),\n                ('categorical', categorical_transformer, self.categorical_features)\n            ], remainder='passthrough')\n        else:\n            # If features not specified, auto-detect (assuming all numeric for simplicity)\n            transformer = Pipeline(steps=[\n                ('imputer', SimpleImputer(strategy='median')),\n                ('scaler', StandardScaler())\n            ])\n\n        if self.models is None:\n            self.models = ['LogisticRegression', 'NaiveBayes', 'DecisionTree', 'RandomForest',\n                          'SVM', 'KNN', 'GBM', 'XGBoost', 'NeuralNetwork', 'AdaBoost', 'XGB-RF']\n        \n        # Select classifier\n        model_type = trial.suggest_categorical('model_type', self.models)\n\n        if model_type == 'LogisticRegression':\n            penalty = trial.suggest_categorical('penalty', ['l2', 'l1'])\n            solver = 'saga' if penalty == 'l1' else 'lbfgs'\n            regularization = trial.suggest_float('Logistic-regularization', 0.01, 500, log=True)\n            model = LogisticRegression(penalty=penalty, C=regularization, solver=solver, random_state=42)\n\n        elif model_type == 'NaiveBayes':\n            model = GaussianNB()\n\n        elif model_type == 'DecisionTree':\n            max_depth = trial.suggest_int('max_depth', 1, 32)\n            min_samples_split = trial.suggest_float('min_samples_split', 0.1, 1.0)\n            min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.1, 0.5)\n            model = DecisionTreeClassifier(max_depth=max_depth,\n                                         min_samples_split=min_samples_split,\n                                         min_samples_leaf=min_samples_leaf,\n                                         random_state=42)\n\n        elif model_type == 'RandomForest':\n            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n            max_depth = trial.suggest_int('max_depth', 1, 10)\n            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n                                         n_jobs=-1, random_state=42)\n\n        elif model_type == 'SVM':\n            C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n            gamma = trial.suggest_float('gamma', 1e-4, 1e4, log=True)\n            kernel = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n            degree = trial.suggest_int('degree', 1, 5)\n            coef0 = trial.suggest_float('coef0', -1.0, 1.0)\n            model = SVC(C=C, gamma=gamma, kernel=kernel, degree=degree, coef0=coef0, random_state=42)\n\n        elif model_type == 'SVC-Bagging':\n            bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n            estimators = trial.suggest_int('n_estimators', 1, 20)\n            model = BaggingClassifier(estimator=SVC(random_state=42), n_estimators=estimators, \n                                    max_samples=bagging_fraction, random_state=42)\n\n        elif model_type == 'KNN-Bagging':\n            bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n            estimators = trial.suggest_int('n_estimators', 1, 20)\n            model = BaggingClassifier(estimator=KNeighborsClassifier(), n_estimators=estimators, \n                                    max_samples=bagging_fraction, random_state=42)\n\n        elif model_type == 'KNN':\n            n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n            weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n            p = trial.suggest_categorical('p', [1, 2])\n            leaf_size = trial.suggest_int('leaf_size', 10, 50)\n            algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n            model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, \n                                       leaf_size=leaf_size, algorithm=algorithm)\n\n        elif model_type == 'GBM':\n            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n            max_depth = trial.suggest_int('max_depth', 1, 20)\n            model = GradientBoostingClassifier(learning_rate=learning_rate, n_estimators=n_estimators, \n                                             max_depth=max_depth, random_state=42)\n\n        elif model_type == 'MLP':\n            hidden_layer_sizes = trial.suggest_int('hidden_layer_sizes', 1, 10, step=1)\n            activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n            solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n            alpha = trial.suggest_float('alpha', 1e-5, 1e-2, log=True)\n            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation,\n                                solver=solver, alpha=alpha, random_state=42)\n\n        elif model_type == 'NeuralNetwork':\n            hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', ['1x100', '2x100'])\n            if hidden_layer_sizes == '1x100':\n                hidden_layer_sizes = (100,)\n            elif hidden_layer_sizes == '2x100':\n                hidden_layer_sizes = (100, 100)\n            activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n            solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, \n                                solver=solver, random_state=42)\n\n        elif model_type == 'XGBoost':\n            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n            max_depth = trial.suggest_int('max_depth', 1, 10)\n            model = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators, \n                                max_depth=max_depth, n_jobs=-1, random_state=42)\n\n        elif model_type == 'AdaBoost':\n            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n            base_estimator = trial.suggest_categorical('base_estimator', ['decision_tree', 'svm', 'random_forest'])\n            \n            if base_estimator == 'decision_tree':\n                max_depth = trial.suggest_int('max_depth', 1, 10)\n                base_model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n            elif base_estimator == 'svm':\n                C = trial.suggest_float('C', 1e-4, 1e+3, log=True)\n                kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n                base_model = SVC(C=C, kernel=kernel, random_state=42)\n            else:\n                n_estimators_rf = trial.suggest_int('n_estimators_rf', 50, 500)\n                max_depth_rf = trial.suggest_int('max_depth_rf', 1, 10)\n                base_model = RandomForestClassifier(n_estimators=n_estimators_rf, max_depth=max_depth_rf, \n                                                  random_state=42)\n\n            model = AdaBoostClassifier(base_estimator=base_model, n_estimators=n_estimators,\n                                     learning_rate=learning_rate, random_state=42)\n\n        elif model_type == 'XGB-RF':\n            params = {\n                'objective': 'binary:logistic',\n                'eval_metric': 'logloss',\n                'booster': 'gbtree',\n                'verbosity': 0,\n                'n_jobs': -1,\n                'random_state': 42,\n                'eta': trial.suggest_float('eta', 0.001, 0.1, log=True),\n                'max_depth': trial.suggest_int('max_depth', 3, 10),\n                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n                'lambda': trial.suggest_float('lambda', 0.001, 10.0),\n                'alpha': trial.suggest_float('alpha', 0.001, 10.0, log=True),\n                'gamma': trial.suggest_float('gamma', 0.001, 10.0, log=True),\n                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n            }\n            model = XGBRFClassifier(**params)\n\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n\n        # Create pipeline with preprocessing and model\n        if self.numeric_features is not None and self.categorical_features is not None:\n            pipeline = Pipeline([\n                ('transformer', transformer),\n                ('model', model)\n            ])\n        else:\n            pipeline = Pipeline([\n                ('imputer', SimpleImputer(strategy='median')),\n                ('scaler', StandardScaler()),\n                ('model', model)\n            ])\n\n        return pipeline\n\n    def objective(self, trial):\n        \"\"\"\n        Define the objective function as the 5-fold cross-validation score\n        trial: number of trials\n        \"\"\"\n        model = self.create_model(trial)\n        scorer = make_scorer(accuracy_score)\n        scores = cross_val_score(model, self.X_train, self.y_train, cv=5, scoring=scorer)\n        return np.mean(scores)\n\n    def AutoML_test(self, n_trials=50):\n        \"\"\"\n        AutoML test function to find the best optimized model\n        n_trials: number of optimization trials (default: 300)\n        \"\"\"\n        start = time()\n        study = optuna.create_study(direction='maximize')\n        study.optimize(self.objective, n_trials=n_trials)\n        best_params = study.best_params\n        print(\"\\n\\nBest parameters: \", best_params)\n\n        best_model = self.create_model(study.best_trial)\n        best_model.fit(self.X_train, self.y_train)\n\n        scores = cross_val_score(best_model, self.X_train, self.y_train, cv=5)\n        print(\"Best cross-validation score: %.5f\" % np.mean(scores))\n        \n        y_pred = best_model.predict(self.X_test)\n        print(\"Accuracy on test data: %.5f\" % accuracy_score(self.y_test, y_pred))\n        print(\"Precision: %.5f\" % precision_score(self.y_test, y_pred))\n        print(\"Recall: %.5f\" % recall_score(self.y_test, y_pred))\n        print(\"F1-score: %.5f\" % f1_score(self.y_test, y_pred))\n        \n        total_time = time() - start\n        print(\"Runtime: %.4f sec\" % total_time)\n        \n        return best_model, best_params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:01:03.762109Z","iopub.execute_input":"2025-07-07T10:01:03.762405Z","iopub.status.idle":"2025-07-07T10:01:05.115557Z","shell.execute_reply.started":"2025-07-07T10:01:03.762384Z","shell.execute_reply":"2025-07-07T10:01:05.114451Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"knn = AutoMLOptuna(X_train, X_val, y_train, y_val, models=['XGBoost'])\nknn.AutoML_test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:49:16.258584Z","iopub.execute_input":"2025-07-07T10:49:16.258954Z","iopub.status.idle":"2025-07-07T10:50:57.349876Z","shell.execute_reply.started":"2025-07-07T10:49:16.258931Z","shell.execute_reply":"2025-07-07T10:50:57.348698Z"}},"outputs":[{"name":"stderr","text":"[I 2025-07-07 10:49:16,260] A new study created in memory with name: no-name-d07917a5-a556-4202-bd43-5e5982fa2aa0\n[I 2025-07-07 10:49:18,002] Trial 0 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0005833637609765607, 'n_estimators': 574, 'max_depth': 2}. Best is trial 0 with value: 0.7395235798418917.\n[I 2025-07-07 10:49:18,765] Trial 1 finished with value: 0.9694310121730766 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.04647937937258573, 'n_estimators': 119, 'max_depth': 6}. Best is trial 1 with value: 0.9694310121730766.\n[I 2025-07-07 10:49:27,665] Trial 2 finished with value: 0.9688911783339551 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.006719719822591066, 'n_estimators': 975, 'max_depth': 10}. Best is trial 1 with value: 0.9694310121730766.\n[I 2025-07-07 10:49:28,822] Trial 3 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0004258742359090905, 'n_estimators': 234, 'max_depth': 7}. Best is trial 1 with value: 0.9694310121730766.\n[I 2025-07-07 10:49:34,767] Trial 4 finished with value: 0.9694310804920606 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.008665082713419023, 'n_estimators': 754, 'max_depth': 6}. Best is trial 4 with value: 0.9694310804920606.\n[I 2025-07-07 10:49:38,458] Trial 5 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.00011309152525945489, 'n_estimators': 730, 'max_depth': 9}. Best is trial 4 with value: 0.9694310804920606.\n[I 2025-07-07 10:49:39,795] Trial 6 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0002325428519182124, 'n_estimators': 229, 'max_depth': 10}. Best is trial 4 with value: 0.9694310804920606.\n[I 2025-07-07 10:49:41,353] Trial 7 finished with value: 0.9697009632521294 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.021106326293588724, 'n_estimators': 506, 'max_depth': 3}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:45,241] Trial 8 finished with value: 0.9694310804920606 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0084295999805728, 'n_estimators': 708, 'max_depth': 6}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:46,294] Trial 9 finished with value: 0.9696334868688634 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.011062375149815262, 'n_estimators': 362, 'max_depth': 2}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:48,129] Trial 10 finished with value: 0.9690936302567472 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.09388032324967596, 'n_estimators': 476, 'max_depth': 4}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:49,033] Trial 11 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.02610225276751243, 'n_estimators': 427, 'max_depth': 1}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:50,024] Trial 12 finished with value: 0.9694985568753266 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.030056011797485415, 'n_estimators': 475, 'max_depth': 1}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:51,285] Trial 13 finished with value: 0.9659893750315975 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0014545323679666477, 'n_estimators': 356, 'max_depth': 4}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:53,234] Trial 14 finished with value: 0.9696334868688634 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.02616560172578321, 'n_estimators': 602, 'max_depth': 3}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:54,095] Trial 15 finished with value: 0.965382155901189 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.003730170144533008, 'n_estimators': 402, 'max_depth': 1}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:57,392] Trial 16 finished with value: 0.9694310349460713 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.01833124415671081, 'n_estimators': 883, 'max_depth': 4}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:49:59,321] Trial 17 finished with value: 0.9694985568753266 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.07926472035301933, 'n_estimators': 617, 'max_depth': 3}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:50:00,104] Trial 18 finished with value: 0.9662593261106502 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0023465475107086473, 'n_estimators': 271, 'max_depth': 2}. Best is trial 7 with value: 0.9697009632521294.\n[I 2025-07-07 10:50:01,088] Trial 19 finished with value: 0.969700986025124 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.016735230477179657, 'n_estimators': 483, 'max_depth': 1}. Best is trial 19 with value: 0.969700986025124.\n[I 2025-07-07 10:50:01,412] Trial 20 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.003832961144508431, 'n_estimators': 56, 'max_depth': 3}. Best is trial 19 with value: 0.969700986025124.\n[I 2025-07-07 10:50:02,441] Trial 21 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0167988137874592, 'n_estimators': 499, 'max_depth': 1}. Best is trial 19 with value: 0.969700986025124.\n[I 2025-07-07 10:50:05,164] Trial 22 finished with value: 0.969700986025124 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.04290146924953239, 'n_estimators': 396, 'max_depth': 1}. Best is trial 19 with value: 0.969700986025124.\n[I 2025-07-07 10:50:06,023] Trial 23 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.04853984977183483, 'n_estimators': 292, 'max_depth': 2}. Best is trial 19 with value: 0.969700986025124.\n[I 2025-07-07 10:50:07,764] Trial 24 finished with value: 0.96976846240839 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.046312462611124816, 'n_estimators': 551, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:10,697] Trial 25 finished with value: 0.9683514128138176 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0573655063594487, 'n_estimators': 678, 'max_depth': 5}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:12,312] Trial 26 finished with value: 0.9695659877126029 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.03734195410803847, 'n_estimators': 830, 'max_depth': 1}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:13,872] Trial 27 finished with value: 0.969700986025124 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.013544610754501163, 'n_estimators': 557, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:16,499] Trial 28 finished with value: 0.9668668412899899 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.09488633711286416, 'n_estimators': 629, 'max_depth': 5}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:17,426] Trial 29 finished with value: 0.9694310577190659 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.005954787154332037, 'n_estimators': 331, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:18,754] Trial 30 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0008417693935456031, 'n_estimators': 431, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:20,170] Trial 31 finished with value: 0.96976846240839 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.016211386405583648, 'n_estimators': 554, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:21,227] Trial 32 finished with value: 0.9696334868688634 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.04107208367450997, 'n_estimators': 515, 'max_depth': 1}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:22,818] Trial 33 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.05727295203969171, 'n_estimators': 572, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:24,416] Trial 34 finished with value: 0.9695659877126029 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.00557065879428323, 'n_estimators': 654, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:28,247] Trial 35 finished with value: 0.9688236791776944 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.01279419797272638, 'n_estimators': 554, 'max_depth': 8}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:28,765] Trial 36 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.06103018456624582, 'n_estimators': 195, 'max_depth': 1}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:31,142] Trial 37 finished with value: 0.96976846240839 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.03418344194340466, 'n_estimators': 805, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:34,074] Trial 38 finished with value: 0.9693635357898106 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.009035246026326452, 'n_estimators': 791, 'max_depth': 4}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:39,712] Trial 39 finished with value: 0.9690936758027366 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0215820876136851, 'n_estimators': 926, 'max_depth': 5}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:41,966] Trial 40 finished with value: 0.9694310349460713 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.03102210234111818, 'n_estimators': 756, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:43,438] Trial 41 finished with value: 0.9696334868688634 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.04261596421625664, 'n_estimators': 406, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:45,310] Trial 42 finished with value: 0.9696335096418582 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.014375273311811095, 'n_estimators': 988, 'max_depth': 1}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:47,110] Trial 43 finished with value: 0.9695660332585924 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.07243167925089657, 'n_estimators': 709, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:47,861] Trial 44 finished with value: 0.9694310121730766 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.033365248421730845, 'n_estimators': 164, 'max_depth': 4}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:50,738] Trial 45 finished with value: 0.9687561800214339 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.022488369276427563, 'n_estimators': 464, 'max_depth': 7}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:52,073] Trial 46 finished with value: 0.9696334868688634 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.00958357574790996, 'n_estimators': 529, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:52,997] Trial 47 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.0001023847476127001, 'n_estimators': 374, 'max_depth': 1}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:54,018] Trial 48 finished with value: 0.7395235798418917 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.00019871881558567107, 'n_estimators': 319, 'max_depth': 3}. Best is trial 24 with value: 0.96976846240839.\n[I 2025-07-07 10:50:55,214] Trial 49 finished with value: 0.96976846240839 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.02488372146622353, 'n_estimators': 448, 'max_depth': 2}. Best is trial 24 with value: 0.96976846240839.\n","output_type":"stream"},{"name":"stdout","text":"\n\nBest parameters:  {'model_type': 'XGBoost', 'learning_rate': 0.046312462611124816, 'n_estimators': 551, 'max_depth': 3}\nBest cross-validation score: 0.96977\nAccuracy on test data: 0.96383\nPrecision: 0.97313\nRecall: 0.97810\nF1-score: 0.97561\nRuntime: 101.0789 sec\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n                 ('scaler', StandardScaler()),\n                 ('model',\n                  XGBClassifier(base_score=None, booster=None, callbacks=None,\n                                colsample_bylevel=None, colsample_bynode=None,\n                                colsample_bytree=None, device=None,\n                                early_stopping_rounds=None,\n                                enable_categorical=False, eval_metric=None,\n                                feature_types=None, gamma=None, grow_policy=None,\n                                importance_type=None,\n                                interaction_constraints=None,\n                                learning_rate=0.046312462611124816, max_bin=None,\n                                max_cat_threshold=None, max_cat_to_onehot=None,\n                                max_delta_step=None, max_depth=3,\n                                max_leaves=None, min_child_weight=None,\n                                missing=nan, monotone_constraints=None,\n                                multi_strategy=None, n_estimators=551, n_jobs=-1,\n                                num_parallel_tree=None, random_state=42, ...))]),\n {'model_type': 'XGBoost',\n  'learning_rate': 0.046312462611124816,\n  'n_estimators': 551,\n  'max_depth': 3})"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# load data\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/test.csv\")\n\n# test data\ntest_data['Stage_fear'] = test_data['Stage_fear'].map({'Yes': 1, 'No': 0})\ntest_data['Drained_after_socializing'] = test_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n\n# KNN\n# params = {'n_neighbors': 8,\n#           'weights': 'uniform',\n#           'p': 1,\n#           'leaf_size': 10,\n#           'algorithm': 'auto'}\n\n# XGBoost\nparams = { 'learning_rate': 0.046312462611124816,\n          'n_estimators': 551,\n          'max_depth': 3}\n\n# # knn model \n# model = KNeighborsClassifier(**params)\n\n# XGBoost\nmodel = XGBClassifier(**params)\n\n# pipeline\npipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), model)\n\n# Fit the knn on the training data\npipeline.fit(X_train, y_train)\n\n# Predict the labels for the test data\npredictions = pipeline.predict(X_val)\n\n# Calculate the evaluation metrics\naccuracy = accuracy_score(y_val, predictions)\nrecall = recall_score(y_val, predictions)\n# precision = precision_score(y_val, predictions)\n# f1 = f1_score(y_val, predictions)\n\nprint(f\"accuracy: {accuracy}\")\nprint(f\"recall: {recall}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:55:06.007673Z","iopub.execute_input":"2025-07-07T10:55:06.008069Z","iopub.status.idle":"2025-07-07T10:55:06.429306Z","shell.execute_reply.started":"2025-07-07T10:55:06.008045Z","shell.execute_reply":"2025-07-07T10:55:06.428114Z"}},"outputs":[{"name":"stdout","text":"accuracy: 0.9638326585695006\nrecall: 0.9781021897810219\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# Test Submission","metadata":{}},{"cell_type":"code","source":"# load data\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/test.csv\")\n\n# test data\ntest_data['Stage_fear'] = test_data['Stage_fear'].map({'Yes': 1, 'No': 0})\ntest_data['Drained_after_socializing'] = test_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n\n# test_data without the 1st column\nX_test = test_data.drop('id',axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:15:19.936960Z","iopub.execute_input":"2025-07-07T10:15:19.937311Z","iopub.status.idle":"2025-07-07T10:15:19.955848Z","shell.execute_reply.started":"2025-07-07T10:15:19.937290Z","shell.execute_reply":"2025-07-07T10:15:19.954345Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:15:21.937602Z","iopub.execute_input":"2025-07-07T10:15:21.937935Z","iopub.status.idle":"2025-07-07T10:15:21.956143Z","shell.execute_reply.started":"2025-07-07T10:15:21.937911Z","shell.execute_reply":"2025-07-07T10:15:21.955073Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n0                  3.0         0.0                      7.0            4.0   \n1                  NaN         1.0                      0.0            0.0   \n2                  3.0         0.0                      5.0            6.0   \n3                  3.0         0.0                      4.0            4.0   \n4                  9.0         1.0                      1.0            2.0   \n...                ...         ...                      ...            ...   \n6170               3.0         0.0                      5.0            5.0   \n6171               8.0         1.0                      2.0            1.0   \n6172               2.0         0.0                      4.0            3.0   \n6173               3.0         0.0                      4.0            4.0   \n6174               NaN         1.0                      1.0            1.0   \n\n      Drained_after_socializing  Friends_circle_size  Post_frequency  \n0                           0.0                  6.0             NaN  \n1                           1.0                  5.0             1.0  \n2                           0.0                 15.0             9.0  \n3                           0.0                  5.0             6.0  \n4                           1.0                  1.0             1.0  \n...                         ...                  ...             ...  \n6170                        0.0                  9.0             6.0  \n6171                        1.0                  0.0             0.0  \n6172                        0.0                  9.0             7.0  \n6173                        0.0                 11.0             9.0  \n6174                        1.0                  1.0             0.0  \n\n[6175 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time_spent_Alone</th>\n      <th>Stage_fear</th>\n      <th>Social_event_attendance</th>\n      <th>Going_outside</th>\n      <th>Drained_after_socializing</th>\n      <th>Friends_circle_size</th>\n      <th>Post_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6170</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6175 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"### K-Nearest Neighbor","metadata":{}},{"cell_type":"code","source":"# params = {'n_neighbors': 8,\n#           'weights': 'uniform',\n#           'p': 1,\n#           'leaf_size': 10,\n#           'algorithm': 'auto'}\n\n# # knn model \n# model = KNeighborsClassifier(**params)\n\n# # pipeline\n# pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), model)\n\n# # Fit the knn on the training data\n# pipeline.fit(X_train, y_train)\n\n# # Predict the labels for the test data\n# predictions = pipeline.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:15:38.497539Z","iopub.execute_input":"2025-07-07T10:15:38.499423Z","iopub.status.idle":"2025-07-07T10:15:39.023357Z","shell.execute_reply.started":"2025-07-07T10:15:38.499370Z","shell.execute_reply":"2025-07-07T10:15:39.022357Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"### XGBoost ","metadata":{}},{"cell_type":"code","source":"# XGBoost\nparams = { 'learning_rate': 0.046312462611124816,\n          'n_estimators': 551,\n          'max_depth': 3}\n\n# # knn model \n# model = KNeighborsClassifier(**params)\n\n# XGBoost\nmodel = XGBClassifier(**params)\n\n# pipeline\npipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), model)\n\n# Fit the knn on the training data\npipeline.fit(X_train, y_train)\n\n# Predict the labels for the test data\npredictions = pipeline.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:57:00.252968Z","iopub.execute_input":"2025-07-07T10:57:00.253327Z","iopub.status.idle":"2025-07-07T10:57:00.655372Z","shell.execute_reply.started":"2025-07-07T10:57:00.253304Z","shell.execute_reply":"2025-07-07T10:57:00.654664Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Get the ID column (first column of test_data)\nids = test_data.iloc[:, 0]\n\n# Map numeric predictions to labels\nlabel_map = {0: \"Introvert\", 1: \"Extrovert\"}\nmapped_predictions = list(map(label_map.get, predictions))\n\n# Combine into a single DataFrame\nresult_df = pd.DataFrame({\n    'id': ids,\n    'Personality': mapped_predictions\n})\n\nprint(result_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:57:04.977371Z","iopub.execute_input":"2025-07-07T10:57:04.977687Z","iopub.status.idle":"2025-07-07T10:57:04.988220Z","shell.execute_reply.started":"2025-07-07T10:57:04.977665Z","shell.execute_reply":"2025-07-07T10:57:04.986879Z"}},"outputs":[{"name":"stdout","text":"      id Personality\n0  18524   Extrovert\n1  18525   Introvert\n2  18526   Extrovert\n3  18527   Extrovert\n4  18528   Introvert\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# output result\nresult_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission file 'submission.csv' saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T10:57:33.934561Z","iopub.execute_input":"2025-07-07T10:57:33.934932Z","iopub.status.idle":"2025-07-07T10:57:33.948817Z","shell.execute_reply.started":"2025-07-07T10:57:33.934907Z","shell.execute_reply":"2025-07-07T10:57:33.947877Z"}},"outputs":[{"name":"stdout","text":"Submission file 'submission.csv' saved.\n","output_type":"stream"}],"execution_count":50}]}