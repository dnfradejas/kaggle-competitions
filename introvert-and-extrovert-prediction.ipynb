{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bee5ef",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:53.720071Z",
     "iopub.status.busy": "2025-07-07T10:29:53.719678Z",
     "iopub.status.idle": "2025-07-07T10:29:55.917251Z",
     "shell.execute_reply": "2025-07-07T10:29:55.916022Z"
    },
    "papermill": {
     "duration": 2.206645,
     "end_time": "2025-07-07T10:29:55.919157",
     "exception": false,
     "start_time": "2025-07-07T10:29:53.712512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s5e7/sample_submission.csv\n",
      "/kaggle/input/playground-series-s5e7/train.csv\n",
      "/kaggle/input/playground-series-s5e7/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b9a9e",
   "metadata": {
    "papermill": {
     "duration": 0.004027,
     "end_time": "2025-07-07T10:29:55.927909",
     "exception": false,
     "start_time": "2025-07-07T10:29:55.923882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfba8211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:55.938153Z",
     "iopub.status.busy": "2025-07-07T10:29:55.937678Z",
     "iopub.status.idle": "2025-07-07T10:29:55.987125Z",
     "shell.execute_reply": "2025-07-07T10:29:55.986173Z"
    },
    "papermill": {
     "duration": 0.056495,
     "end_time": "2025-07-07T10:29:55.988908",
     "exception": false,
     "start_time": "2025-07-07T10:29:55.932413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3816dcd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:55.998864Z",
     "iopub.status.busy": "2025-07-07T10:29:55.998559Z",
     "iopub.status.idle": "2025-07-07T10:29:56.032700Z",
     "shell.execute_reply": "2025-07-07T10:29:56.031667Z"
    },
    "papermill": {
     "duration": 0.04153,
     "end_time": "2025-07-07T10:29:56.034809",
     "exception": false,
     "start_time": "2025-07-07T10:29:55.993279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18524 entries, 0 to 18523\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         18524 non-null  int64  \n",
      " 1   Time_spent_Alone           17334 non-null  float64\n",
      " 2   Stage_fear                 16631 non-null  object \n",
      " 3   Social_event_attendance    17344 non-null  float64\n",
      " 4   Going_outside              17058 non-null  float64\n",
      " 5   Drained_after_socializing  17375 non-null  object \n",
      " 6   Friends_circle_size        17470 non-null  float64\n",
      " 7   Post_frequency             17260 non-null  float64\n",
      " 8   Personality                18524 non-null  object \n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64c5799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.044952Z",
     "iopub.status.busy": "2025-07-07T10:29:56.044639Z",
     "iopub.status.idle": "2025-07-07T10:29:56.060686Z",
     "shell.execute_reply": "2025-07-07T10:29:56.059791Z"
    },
    "papermill": {
     "duration": 0.022865,
     "end_time": "2025-07-07T10:29:56.062148",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.039283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           18524\n",
       "Time_spent_Alone                12\n",
       "Stage_fear                       2\n",
       "Social_event_attendance         11\n",
       "Going_outside                    8\n",
       "Drained_after_socializing        2\n",
       "Friends_circle_size             16\n",
       "Post_frequency                  11\n",
       "Personality                      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f663da",
   "metadata": {
    "papermill": {
     "duration": 0.004379,
     "end_time": "2025-07-07T10:29:56.071561",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.067182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Converting text data to binomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb619583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.081717Z",
     "iopub.status.busy": "2025-07-07T10:29:56.081414Z",
     "iopub.status.idle": "2025-07-07T10:29:56.098488Z",
     "shell.execute_reply": "2025-07-07T10:29:56.096845Z"
    },
    "papermill": {
     "duration": 0.024308,
     "end_time": "2025-07-07T10:29:56.100307",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.075999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage_fear\n",
      "No     12609\n",
      "Yes     4022\n",
      "Name: count, dtype: int64\n",
      "['No' 'Yes' nan]\n",
      "\n",
      "\n",
      "Drained_after_socializing\n",
      "No     13313\n",
      "Yes     4062\n",
      "Name: count, dtype: int64\n",
      "['No' nan 'Yes']\n",
      "\n",
      "\n",
      "Personality\n",
      "Extrovert    13699\n",
      "Introvert     4825\n",
      "Name: count, dtype: int64\n",
      "['Extrovert' 'Introvert']\n"
     ]
    }
   ],
   "source": [
    "# convert text data to numerical data Stage\n",
    "# Check what you're working with\n",
    "print(train_data['Stage_fear'].value_counts())\n",
    "print(train_data['Stage_fear'].unique())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(train_data['Drained_after_socializing'].value_counts())\n",
    "print(train_data['Drained_after_socializing'].unique())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(train_data['Personality'].value_counts())\n",
    "print(train_data['Personality'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b446d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.110914Z",
     "iopub.status.busy": "2025-07-07T10:29:56.110173Z",
     "iopub.status.idle": "2025-07-07T10:29:56.125023Z",
     "shell.execute_reply": "2025-07-07T10:29:56.123871Z"
    },
    "papermill": {
     "duration": 0.022077,
     "end_time": "2025-07-07T10:29:56.126980",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.104903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to binary\n",
    "# train data\n",
    "train_data['Stage_fear'] = train_data['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "train_data['Drained_after_socializing'] = train_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "train_data['Personality'] = train_data['Personality'].map({'Extrovert': 1, 'Introvert': 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e6a753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.137748Z",
     "iopub.status.busy": "2025-07-07T10:29:56.137313Z",
     "iopub.status.idle": "2025-07-07T10:29:56.170248Z",
     "shell.execute_reply": "2025-07-07T10:29:56.169176Z"
    },
    "papermill": {
     "duration": 0.040067,
     "end_time": "2025-07-07T10:29:56.171871",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.131804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18519</th>\n",
       "      <td>18519</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18520</th>\n",
       "      <td>18520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18521</th>\n",
       "      <td>18521</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18522</th>\n",
       "      <td>18522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18523</th>\n",
       "      <td>18523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18524 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Time_spent_Alone  Stage_fear  Social_event_attendance  \\\n",
       "0          0               0.0         0.0                      6.0   \n",
       "1          1               1.0         0.0                      7.0   \n",
       "2          2               6.0         1.0                      1.0   \n",
       "3          3               3.0         0.0                      7.0   \n",
       "4          4               1.0         0.0                      4.0   \n",
       "...      ...               ...         ...                      ...   \n",
       "18519  18519               3.0         0.0                      7.0   \n",
       "18520  18520               1.0         NaN                      6.0   \n",
       "18521  18521               7.0         1.0                      1.0   \n",
       "18522  18522               NaN         1.0                      1.0   \n",
       "18523  18523               1.0         0.0                      8.0   \n",
       "\n",
       "       Going_outside  Drained_after_socializing  Friends_circle_size  \\\n",
       "0                4.0                        0.0                 15.0   \n",
       "1                3.0                        0.0                 10.0   \n",
       "2                0.0                        NaN                  3.0   \n",
       "3                3.0                        0.0                 11.0   \n",
       "4                4.0                        0.0                 13.0   \n",
       "...              ...                        ...                  ...   \n",
       "18519            3.0                        0.0                  9.0   \n",
       "18520            7.0                        0.0                  6.0   \n",
       "18521            1.0                        1.0                  1.0   \n",
       "18522            0.0                        1.0                  5.0   \n",
       "18523            6.0                        0.0                  4.0   \n",
       "\n",
       "       Post_frequency  Personality  \n",
       "0                 5.0            1  \n",
       "1                 8.0            1  \n",
       "2                 0.0            0  \n",
       "3                 5.0            1  \n",
       "4                 NaN            1  \n",
       "...               ...          ...  \n",
       "18519             7.0            1  \n",
       "18520             5.0            1  \n",
       "18521             NaN            0  \n",
       "18522             2.0            0  \n",
       "18523             7.0            1  \n",
       "\n",
       "[18524 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea20b349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.183210Z",
     "iopub.status.busy": "2025-07-07T10:29:56.182893Z",
     "iopub.status.idle": "2025-07-07T10:29:56.190930Z",
     "shell.execute_reply": "2025-07-07T10:29:56.189881Z"
    },
    "papermill": {
     "duration": 0.015822,
     "end_time": "2025-07-07T10:29:56.192651",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.176829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba47d4",
   "metadata": {
    "papermill": {
     "duration": 0.005084,
     "end_time": "2025-07-07T10:29:56.202924",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.197840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0872dc98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.213927Z",
     "iopub.status.busy": "2025-07-07T10:29:56.213611Z",
     "iopub.status.idle": "2025-07-07T10:29:56.232308Z",
     "shell.execute_reply": "2025-07-07T10:29:56.231269Z"
    },
    "papermill": {
     "duration": 0.026165,
     "end_time": "2025-07-07T10:29:56.233892",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.207727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18519</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18520</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18521</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18522</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18524 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0                   0.0         0.0                      6.0            4.0   \n",
       "1                   1.0         0.0                      7.0            3.0   \n",
       "2                   6.0         1.0                      1.0            0.0   \n",
       "3                   3.0         0.0                      7.0            3.0   \n",
       "4                   1.0         0.0                      4.0            4.0   \n",
       "...                 ...         ...                      ...            ...   \n",
       "18519               3.0         0.0                      7.0            3.0   \n",
       "18520               1.0         NaN                      6.0            7.0   \n",
       "18521               7.0         1.0                      1.0            1.0   \n",
       "18522               NaN         1.0                      1.0            0.0   \n",
       "18523               1.0         0.0                      8.0            6.0   \n",
       "\n",
       "       Drained_after_socializing  Friends_circle_size  Post_frequency  \n",
       "0                            0.0                 15.0             5.0  \n",
       "1                            0.0                 10.0             8.0  \n",
       "2                            NaN                  3.0             0.0  \n",
       "3                            0.0                 11.0             5.0  \n",
       "4                            0.0                 13.0             NaN  \n",
       "...                          ...                  ...             ...  \n",
       "18519                        0.0                  9.0             7.0  \n",
       "18520                        0.0                  6.0             5.0  \n",
       "18521                        1.0                  1.0             NaN  \n",
       "18522                        1.0                  5.0             2.0  \n",
       "18523                        0.0                  4.0             7.0  \n",
       "\n",
       "[18524 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605d14af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:56.246027Z",
     "iopub.status.busy": "2025-07-07T10:29:56.245712Z",
     "iopub.status.idle": "2025-07-07T10:29:58.281407Z",
     "shell.execute_reply": "2025-07-07T10:29:58.280232Z"
    },
    "papermill": {
     "duration": 2.044162,
     "end_time": "2025-07-07T10:29:58.283466",
     "exception": false,
     "start_time": "2025-07-07T10:29:56.239304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = train_data.iloc[:, :-1].copy()\n",
    "\n",
    "y = train_data['Personality'].copy()\n",
    "\n",
    "# Split into 80% train, 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for validation\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=y          # Maintains class distribution (for classification)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20640035",
   "metadata": {
    "papermill": {
     "duration": 0.005019,
     "end_time": "2025-07-07T10:29:58.294008",
     "exception": false,
     "start_time": "2025-07-07T10:29:58.288989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AutomML Approach using Optuna Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9da6e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:58.306874Z",
     "iopub.status.busy": "2025-07-07T10:29:58.306236Z",
     "iopub.status.idle": "2025-07-07T10:29:59.498863Z",
     "shell.execute_reply": "2025-07-07T10:29:59.497878Z"
    },
    "papermill": {
     "duration": 1.201518,
     "end_time": "2025-07-07T10:29:59.500585",
     "exception": false,
     "start_time": "2025-07-07T10:29:58.299067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "import optuna\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# create an OptunaAutoML Class\n",
    "class AutoMLOptuna:\n",
    "    \"\"\"\n",
    "    An AutoML Algorithm to search for the best algorithm for binary classification\n",
    "    Uses StandardScaler for scaling and SimpleImputer for handling missing values.\n",
    "    Includes SVC, XGBoost, SVM, LDA, RandomForest, Neural Network, Naive Bayes, and Decision Trees\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, numeric_features=None, categorical_features=None, models=None):\n",
    "        \"\"\"\n",
    "        X_train, X_test: Input training and test data\n",
    "        y_train, y_test: Input binary classification labels (0 and 1)\n",
    "        numeric_features: List of numeric column names\n",
    "        categorical_features: List of categorical column names\n",
    "        models: List of specific models to use (optional)\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.models = models\n",
    "\n",
    "    def create_model(self, trial, models=None):\n",
    "        # Create preprocessing pipeline with SimpleImputer and StandardScaler\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "            ('scaler', StandardScaler())  # Standard scaling only\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent'))  # Handle missing categorical values\n",
    "        ])\n",
    "\n",
    "        # Column transformer\n",
    "        if self.numeric_features is not None and self.categorical_features is not None:\n",
    "            transformer = ColumnTransformer([\n",
    "                ('numeric', numeric_transformer, self.numeric_features),\n",
    "                ('categorical', categorical_transformer, self.categorical_features)\n",
    "            ], remainder='passthrough')\n",
    "        else:\n",
    "            # If features not specified, auto-detect (assuming all numeric for simplicity)\n",
    "            transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "\n",
    "        if self.models is None:\n",
    "            self.models = ['LogisticRegression', 'NaiveBayes', 'DecisionTree', 'RandomForest',\n",
    "                          'SVM', 'KNN', 'GBM', 'XGBoost', 'NeuralNetwork', 'AdaBoost', 'XGB-RF']\n",
    "        \n",
    "        # Select classifier\n",
    "        model_type = trial.suggest_categorical('model_type', self.models)\n",
    "\n",
    "        if model_type == 'LogisticRegression':\n",
    "            penalty = trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "            solver = 'saga' if penalty == 'l1' else 'lbfgs'\n",
    "            regularization = trial.suggest_float('Logistic-regularization', 0.01, 500, log=True)\n",
    "            model = LogisticRegression(penalty=penalty, C=regularization, solver=solver, random_state=42)\n",
    "\n",
    "        elif model_type == 'NaiveBayes':\n",
    "            model = GaussianNB()\n",
    "\n",
    "        elif model_type == 'DecisionTree':\n",
    "            max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "            min_samples_split = trial.suggest_float('min_samples_split', 0.1, 1.0)\n",
    "            min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.1, 0.5)\n",
    "            model = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                         min_samples_split=min_samples_split,\n",
    "                                         min_samples_leaf=min_samples_leaf,\n",
    "                                         random_state=42)\n",
    "\n",
    "        elif model_type == 'RandomForest':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                         n_jobs=-1, random_state=42)\n",
    "\n",
    "        elif model_type == 'SVM':\n",
    "            C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
    "            gamma = trial.suggest_float('gamma', 1e-4, 1e4, log=True)\n",
    "            kernel = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "            degree = trial.suggest_int('degree', 1, 5)\n",
    "            coef0 = trial.suggest_float('coef0', -1.0, 1.0)\n",
    "            model = SVC(C=C, gamma=gamma, kernel=kernel, degree=degree, coef0=coef0, random_state=42)\n",
    "\n",
    "        elif model_type == 'SVC-Bagging':\n",
    "            bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "            estimators = trial.suggest_int('n_estimators', 1, 20)\n",
    "            model = BaggingClassifier(estimator=SVC(random_state=42), n_estimators=estimators, \n",
    "                                    max_samples=bagging_fraction, random_state=42)\n",
    "\n",
    "        elif model_type == 'KNN-Bagging':\n",
    "            bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "            estimators = trial.suggest_int('n_estimators', 1, 20)\n",
    "            model = BaggingClassifier(estimator=KNeighborsClassifier(), n_estimators=estimators, \n",
    "                                    max_samples=bagging_fraction, random_state=42)\n",
    "\n",
    "        elif model_type == 'KNN':\n",
    "            n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
    "            weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "            p = trial.suggest_categorical('p', [1, 2])\n",
    "            leaf_size = trial.suggest_int('leaf_size', 10, 50)\n",
    "            algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "            model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, \n",
    "                                       leaf_size=leaf_size, algorithm=algorithm)\n",
    "\n",
    "        elif model_type == 'GBM':\n",
    "            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "            model = GradientBoostingClassifier(learning_rate=learning_rate, n_estimators=n_estimators, \n",
    "                                             max_depth=max_depth, random_state=42)\n",
    "\n",
    "        elif model_type == 'MLP':\n",
    "            hidden_layer_sizes = trial.suggest_int('hidden_layer_sizes', 1, 10, step=1)\n",
    "            activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n",
    "            solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "            alpha = trial.suggest_float('alpha', 1e-5, 1e-2, log=True)\n",
    "            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation,\n",
    "                                solver=solver, alpha=alpha, random_state=42)\n",
    "\n",
    "        elif model_type == 'NeuralNetwork':\n",
    "            hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', ['1x100', '2x100'])\n",
    "            if hidden_layer_sizes == '1x100':\n",
    "                hidden_layer_sizes = (100,)\n",
    "            elif hidden_layer_sizes == '2x100':\n",
    "                hidden_layer_sizes = (100, 100)\n",
    "            activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "            solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, \n",
    "                                solver=solver, random_state=42)\n",
    "\n",
    "        elif model_type == 'XGBoost':\n",
    "            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "            model = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators, \n",
    "                                max_depth=max_depth, n_jobs=-1, random_state=42)\n",
    "\n",
    "        elif model_type == 'AdaBoost':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "            base_estimator = trial.suggest_categorical('base_estimator', ['decision_tree', 'svm', 'random_forest'])\n",
    "            \n",
    "            if base_estimator == 'decision_tree':\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "                base_model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "            elif base_estimator == 'svm':\n",
    "                C = trial.suggest_float('C', 1e-4, 1e+3, log=True)\n",
    "                kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "                base_model = SVC(C=C, kernel=kernel, random_state=42)\n",
    "            else:\n",
    "                n_estimators_rf = trial.suggest_int('n_estimators_rf', 50, 500)\n",
    "                max_depth_rf = trial.suggest_int('max_depth_rf', 1, 10)\n",
    "                base_model = RandomForestClassifier(n_estimators=n_estimators_rf, max_depth=max_depth_rf, \n",
    "                                                  random_state=42)\n",
    "\n",
    "            model = AdaBoostClassifier(base_estimator=base_model, n_estimators=n_estimators,\n",
    "                                     learning_rate=learning_rate, random_state=42)\n",
    "\n",
    "        elif model_type == 'XGB-RF':\n",
    "            params = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss',\n",
    "                'booster': 'gbtree',\n",
    "                'verbosity': 0,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42,\n",
    "                'eta': trial.suggest_float('eta', 0.001, 0.1, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'lambda': trial.suggest_float('lambda', 0.001, 10.0),\n",
    "                'alpha': trial.suggest_float('alpha', 0.001, 10.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 0.001, 10.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            }\n",
    "            model = XGBRFClassifier(**params)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        # Create pipeline with preprocessing and model\n",
    "        if self.numeric_features is not None and self.categorical_features is not None:\n",
    "            pipeline = Pipeline([\n",
    "                ('transformer', transformer),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "        return pipeline\n",
    "\n",
    "    def objective(self, trial):\n",
    "        \"\"\"\n",
    "        Define the objective function as the 5-fold cross-validation score\n",
    "        trial: number of trials\n",
    "        \"\"\"\n",
    "        model = self.create_model(trial)\n",
    "        scorer = make_scorer(accuracy_score)\n",
    "        scores = cross_val_score(model, self.X_train, self.y_train, cv=5, scoring=scorer)\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def AutoML_test(self, n_trials=50):\n",
    "        \"\"\"\n",
    "        AutoML test function to find the best optimized model\n",
    "        n_trials: number of optimization trials (default: 300)\n",
    "        \"\"\"\n",
    "        start = time()\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=n_trials)\n",
    "        best_params = study.best_params\n",
    "        print(\"\\n\\nBest parameters: \", best_params)\n",
    "\n",
    "        best_model = self.create_model(study.best_trial)\n",
    "        best_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        scores = cross_val_score(best_model, self.X_train, self.y_train, cv=5)\n",
    "        print(\"Best cross-validation score: %.5f\" % np.mean(scores))\n",
    "        \n",
    "        y_pred = best_model.predict(self.X_test)\n",
    "        print(\"Accuracy on test data: %.5f\" % accuracy_score(self.y_test, y_pred))\n",
    "        print(\"Precision: %.5f\" % precision_score(self.y_test, y_pred))\n",
    "        print(\"Recall: %.5f\" % recall_score(self.y_test, y_pred))\n",
    "        print(\"F1-score: %.5f\" % f1_score(self.y_test, y_pred))\n",
    "        \n",
    "        total_time = time() - start\n",
    "        print(\"Runtime: %.4f sec\" % total_time)\n",
    "        \n",
    "        return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f553e38a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:59.513166Z",
     "iopub.status.busy": "2025-07-07T10:29:59.512810Z",
     "iopub.status.idle": "2025-07-07T10:29:59.895700Z",
     "shell.execute_reply": "2025-07-07T10:29:59.894854Z"
    },
    "papermill": {
     "duration": 0.391057,
     "end_time": "2025-07-07T10:29:59.897260",
     "exception": false,
     "start_time": "2025-07-07T10:29:59.506203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9651821862348178\n",
      "recall: 0.9795620437956204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "test_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/test.csv\")\n",
    "\n",
    "# test data\n",
    "test_data['Stage_fear'] = test_data['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "test_data['Drained_after_socializing'] = test_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "params = {'n_neighbors': 8,\n",
    "          'weights': 'uniform',\n",
    "          'p': 1,\n",
    "          'leaf_size': 10,\n",
    "          'algorithm': 'auto'}\n",
    "\n",
    "# knn model \n",
    "model = KNeighborsClassifier(**params)\n",
    "\n",
    "# pipeline\n",
    "pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), model)\n",
    "\n",
    "# Fit the knn on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "predictions = pipeline.predict(X_val)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "# precision = precision_score(y_val, predictions)\n",
    "# f1 = f1_score(y_val, predictions)\n",
    "\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "print(f\"recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb5f05",
   "metadata": {
    "papermill": {
     "duration": 0.004817,
     "end_time": "2025-07-07T10:29:59.907628",
     "exception": false,
     "start_time": "2025-07-07T10:29:59.902811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c20a647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:59.919113Z",
     "iopub.status.busy": "2025-07-07T10:29:59.918813Z",
     "iopub.status.idle": "2025-07-07T10:29:59.934654Z",
     "shell.execute_reply": "2025-07-07T10:29:59.933780Z"
    },
    "papermill": {
     "duration": 0.023643,
     "end_time": "2025-07-07T10:29:59.936416",
     "exception": false,
     "start_time": "2025-07-07T10:29:59.912773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "test_data = pd.read_csv(\"/kaggle/input/playground-series-s5e7/test.csv\")\n",
    "\n",
    "# test data\n",
    "test_data['Stage_fear'] = test_data['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "test_data['Drained_after_socializing'] = test_data['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# test_data without the 1st column\n",
    "X_test = test_data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d502f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:59.948708Z",
     "iopub.status.busy": "2025-07-07T10:29:59.948394Z",
     "iopub.status.idle": "2025-07-07T10:29:59.965989Z",
     "shell.execute_reply": "2025-07-07T10:29:59.964750Z"
    },
    "papermill": {
     "duration": 0.025309,
     "end_time": "2025-07-07T10:29:59.967472",
     "exception": false,
     "start_time": "2025-07-07T10:29:59.942163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6175 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0                  3.0         0.0                      7.0            4.0   \n",
       "1                  NaN         1.0                      0.0            0.0   \n",
       "2                  3.0         0.0                      5.0            6.0   \n",
       "3                  3.0         0.0                      4.0            4.0   \n",
       "4                  9.0         1.0                      1.0            2.0   \n",
       "...                ...         ...                      ...            ...   \n",
       "6170               3.0         0.0                      5.0            5.0   \n",
       "6171               8.0         1.0                      2.0            1.0   \n",
       "6172               2.0         0.0                      4.0            3.0   \n",
       "6173               3.0         0.0                      4.0            4.0   \n",
       "6174               NaN         1.0                      1.0            1.0   \n",
       "\n",
       "      Drained_after_socializing  Friends_circle_size  Post_frequency  \n",
       "0                           0.0                  6.0             NaN  \n",
       "1                           1.0                  5.0             1.0  \n",
       "2                           0.0                 15.0             9.0  \n",
       "3                           0.0                  5.0             6.0  \n",
       "4                           1.0                  1.0             1.0  \n",
       "...                         ...                  ...             ...  \n",
       "6170                        0.0                  9.0             6.0  \n",
       "6171                        1.0                  0.0             0.0  \n",
       "6172                        0.0                  9.0             7.0  \n",
       "6173                        0.0                 11.0             9.0  \n",
       "6174                        1.0                  1.0             0.0  \n",
       "\n",
       "[6175 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b081edd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:29:59.980933Z",
     "iopub.status.busy": "2025-07-07T10:29:59.980630Z",
     "iopub.status.idle": "2025-07-07T10:30:00.545977Z",
     "shell.execute_reply": "2025-07-07T10:30:00.545056Z"
    },
    "papermill": {
     "duration": 0.574158,
     "end_time": "2025-07-07T10:30:00.547813",
     "exception": false,
     "start_time": "2025-07-07T10:29:59.973655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'n_neighbors': 8,\n",
    "          'weights': 'uniform',\n",
    "          'p': 1,\n",
    "          'leaf_size': 10,\n",
    "          'algorithm': 'auto'}\n",
    "\n",
    "# knn model \n",
    "model = KNeighborsClassifier(**params)\n",
    "\n",
    "# pipeline\n",
    "pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), model)\n",
    "\n",
    "# Fit the knn on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc17bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:30:00.561015Z",
     "iopub.status.busy": "2025-07-07T10:30:00.560680Z",
     "iopub.status.idle": "2025-07-07T10:30:00.570480Z",
     "shell.execute_reply": "2025-07-07T10:30:00.569390Z"
    },
    "papermill": {
     "duration": 0.018124,
     "end_time": "2025-07-07T10:30:00.572079",
     "exception": false,
     "start_time": "2025-07-07T10:30:00.553955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id Personality\n",
      "0  18524   Extrovert\n",
      "1  18525   Introvert\n",
      "2  18526   Extrovert\n",
      "3  18527   Extrovert\n",
      "4  18528   Introvert\n"
     ]
    }
   ],
   "source": [
    "# Get the ID column (first column of test_data)\n",
    "ids = test_data.iloc[:, 0]\n",
    "\n",
    "# Map numeric predictions to labels\n",
    "label_map = {0: \"Introvert\", 1: \"Extrovert\"}\n",
    "mapped_predictions = list(map(label_map.get, predictions))\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'Personality': mapped_predictions\n",
    "})\n",
    "\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e8939d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:30:00.584891Z",
     "iopub.status.busy": "2025-07-07T10:30:00.584551Z",
     "iopub.status.idle": "2025-07-07T10:30:00.603394Z",
     "shell.execute_reply": "2025-07-07T10:30:00.602215Z"
    },
    "papermill": {
     "duration": 0.027571,
     "end_time": "2025-07-07T10:30:00.605295",
     "exception": false,
     "start_time": "2025-07-07T10:30:00.577724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output result\n",
    "result_df.to_csv('submission_v1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12738969,
     "sourceId": 91718,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.962676,
   "end_time": "2025-07-07T10:30:01.333623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T10:29:48.370947",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
